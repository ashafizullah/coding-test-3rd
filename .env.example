# LLM Provider (openai, groq, ollama, anthropic)
LLM_PROVIDER=groq

# Groq API (Free, Fast - Recommended for Development)
# Get free API key from: https://console.groq.com
GROQ_API_KEY=gsk-your-groq-api-key-here
GROQ_MODEL=llama-3.3-70b-versatile

# OpenAI API Key (Optional - if using OpenAI as LLM provider)
OPENAI_API_KEY=sk-your-api-key-here

# OpenAI Models (Optional - defaults provided)
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Anthropic (Optional)
ANTHROPIC_API_KEY=

# Ollama (Optional - for local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Database (Configured in docker-compose.yml)
DATABASE_URL=postgresql://funduser:fundpass@postgres:5432/funddb

# Redis (Configured in docker-compose.yml)
REDIS_URL=redis://redis:6379/0

# Celery
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/1
